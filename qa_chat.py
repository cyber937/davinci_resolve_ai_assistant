import os
import textwrap
from langchain.chains import RetrievalQA
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_openai import ChatOpenAI

def format_response(text: str, width: int = 80) -> str:
    """æ•´å½¢ã•ã‚ŒãŸå›ç­”ã‚’è¿”ã™"""
    return textwrap.fill(text.strip(), width=width)

def main():
    print("ğŸ§  Loading vector index...")
    try:
        db = FAISS.load_local(
            folder_path="vector_index",
            embeddings=OpenAIEmbeddings(openai_api_key=os.environ.get("OPENAI_API_KEY")),
            allow_dangerous_deserialization=True
        )
    except Exception as e:
        print(f"âŒ Failed to load vector index: {e}")
        return

    retriever = db.as_retriever()
    qa_chain = RetrievalQA.from_chain_type(
        llm=ChatOpenAI(model="gpt-4", temperature=0),
        retriever=retriever
    )

    print("âœ… Ready! Ask a question about DaVinci Resolve.")
    print("Type 'exit' to quit.\n")

    while True:
        query = input("ğŸ—£ï¸ You: ").strip()
        if query.lower() in ["exit", "quit"]:
            print("ğŸ‘‹ Goodbye!")
            break
        if not query:
            continue  # ç©ºå…¥åŠ›ã‚’ç„¡è¦–

        try:
            response = qa_chain.invoke({"query": query})
            result = response.get("result", "No result found.")
            formatted = format_response(result)
            print("\nğŸ¤– AI Response:\n")
            print(formatted)
        except Exception as e:
            print(f"âš ï¸ Error during query: {e}")

        print("-" * 50)

if __name__ == "__main__":
    main()